{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46734ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from cleaning_and_preprocessing_function import clean_n_preprocess\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae825b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../dataset/port_operations_log.csv\")\n",
    "X = df.drop(columns=['Actual_Operation_Duration_Hours'])\n",
    "y = df['Actual_Operation_Duration_Hours']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed1205",
   "metadata": {},
   "source": [
    "### Split dataset into train/test \n",
    "Split the dataset into train/test first THEN preprocess only the training dataset to ensure no data leakage (to prevent info from the supposedly unseen test data from influencing the preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1392f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_processed = clean_n_preprocess(X_train)\n",
    "X_test_processed = clean_n_preprocess(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553ec6fc",
   "metadata": {},
   "source": [
    "### Baseline & Challenger models\n",
    "1. Linear Regression\n",
    "2. Ridge Regression\n",
    "3. Lasso Regression\n",
    "4. Decision Tree Regression\n",
    "5. Random Forest Regression\n",
    "6. Gradient Boosting Regression\n",
    "7. Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d790961f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Linear Regression Performance ---\n",
      "MAE: 19.70 hours\n",
      "RMSE: 26.49 hours\n",
      "R-squared: 0.84\n",
      "--- Ridge Regression Performance ---\n",
      "MAE: 19.70 hours\n",
      "RMSE: 26.50 hours\n",
      "R-squared: 0.84\n",
      "--- Lasso Regression Performance ---\n",
      "MAE: 19.70 hours\n",
      "RMSE: 26.50 hours\n",
      "R-squared: 0.84\n",
      "--- Decision Tree Regression Performance ---\n",
      "MAE: 10.60 hours\n",
      "RMSE: 14.52 hours\n",
      "R-squared: 0.95\n",
      "--- Random Forest Regression Performance ---\n",
      "MAE: 9.08 hours\n",
      "RMSE: 12.94 hours\n",
      "R-squared: 0.96\n",
      "--- Gradient Boost Regression Performance ---\n",
      "MAE: 9.16 hours\n",
      "RMSE: 12.89 hours\n",
      "R-squared: 0.96\n",
      "--- Support Vector Regression Performance ---\n",
      "MAE: 18.77 hours\n",
      "RMSE: 32.42 hours\n",
      "R-squared: 0.77\n"
     ]
    }
   ],
   "source": [
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_processed, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_processed)\n",
    "print(\"--- Linear Regression Performance ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_lr):.2f} hours\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lr)):.2f} hours\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred_lr):.2f}\")\n",
    "\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0)\n",
    "ridge_model.fit(X_train_processed, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test_processed)\n",
    "print(\"--- Ridge Regression Performance ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_ridge):.2f} hours\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_ridge)):.2f} hours\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred_ridge):.2f}\")\n",
    "\n",
    "\n",
    "lasso_model = Lasso(alpha=1.0)\n",
    "ridge_model.fit(X_train_processed, y_train)\n",
    "y_pred_lasso = ridge_model.predict(X_test_processed)\n",
    "print(\"--- Lasso Regression Performance ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_lasso):.2f} hours\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lasso)):.2f} hours\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred_lasso):.2f}\")\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeRegressor(max_depth=5, random_state=42) # Hyperparameters to tune\n",
    "dt_model.fit(X_train_processed, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test_processed)\n",
    "print(\"--- Decision Tree Regression Performance ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_dt):.2f} hours\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_dt)):.2f} hours\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred_dt):.2f}\")\n",
    "\n",
    "\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1) # Hyperparameters to tune\n",
    "rf_model.fit(X_train_processed, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test_processed)\n",
    "print(\"--- Random Forest Regression Performance ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_rf):.2f} hours\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_rf)):.2f} hours\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred_rf):.2f}\")\n",
    "\n",
    "\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train_processed, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test_processed)\n",
    "print(\"--- Gradient Boost Regression Performance ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_gb):.2f} hours\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_gb)):.2f} hours\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred_gb):.2f}\")\n",
    "\n",
    "\n",
    "svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1) # Hyperparameters to tune\n",
    "svr_model.fit(X_train_processed, y_train)\n",
    "y_pred_svr = svr_model.predict(X_test_processed)\n",
    "print(\"--- Support Vector Regression Performance ---\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred_svr):.2f} hours\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_svr)):.2f} hours\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred_svr):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e62bc",
   "metadata": {},
   "source": [
    "From a quick evaluation (looking only at 3 metrics: MAE, RMSE, R-squared), the top 3 best performing models before hyperparameter tuning are\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- Gradient Boost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
